{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb50d888",
   "metadata": {},
   "source": [
    "# W7 Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d42161e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup\n",
    "import sys\n",
    "# Python 3.7 is required\n",
    "assert sys.version_info >= (3,7)\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make sure that optimization is enabled\n",
    "if not cv.useOptimized():\n",
    "    cv.setUseOptimized(True)\n",
    "\n",
    "cv.useOptimized()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be78b194",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c03ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('lena.jfif', 0) #grayscale\n",
    "\n",
    "# Histogram Equalization\n",
    "eq = cv.equalizeHist(img)\n",
    "\n",
    "# 2nd Histogram Equalization\n",
    "dst = cv.equalizeHist(eq)\n",
    "\n",
    "cv.imshow('result', np.hstack((img, eq, dst)))\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8948d99d",
   "metadata": {},
   "source": [
    "There is no changes between 2 images.\n",
    "The value of the histogram equalization will not change while it is multiplied by itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a3fbc7",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd7869b",
   "metadata": {},
   "source": [
    "### part a: different kernel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61ff4041",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('electronic.jfif', 0)\n",
    "\n",
    "laplacian1 = cv.Laplacian(img, cv.CV_64F, ksize = 1)\n",
    "laplacian1_8u = np.uint8(np.absolute(laplacian1))\n",
    "\n",
    "laplacian2 = cv.Laplacian(img, cv.CV_64F, ksize = 3)\n",
    "laplacian2_8u = np.uint8(np.absolute(laplacian2))\n",
    "\n",
    "laplacian3 = cv.Laplacian(img, cv.CV_64F, ksize = 5)\n",
    "laplacian3_8u = np.uint8(np.absolute(laplacian3))\n",
    "\n",
    "laplacian4 = cv.Laplacian(img, cv.CV_64F, ksize = 7)\n",
    "laplacian4_8u = np.uint8(np.absolute(laplacian4))\n",
    "\n",
    "cv.imshow('result', np.hstack((laplacian1_8u, laplacian2_8u, laplacian3_8u, laplacian4_8u)))\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5702750a",
   "metadata": {},
   "source": [
    "The smaller kernel size is preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a0fec1",
   "metadata": {},
   "source": [
    "### part b: sobel with combined x and y with and without Gaussian blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "100e9304",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('electronic.jfif', 0)\n",
    "img_blur = cv.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "sobelx_normal = cv.Sobel(img, cv.CV_64F, 1, 0, ksize = 3)\n",
    "sobelx_8u_normal = np.uint8(np.absolute(sobelx_normal))\n",
    "\n",
    "sobely_normal = cv.Sobel(img, cv.CV_64F, 0, 1, ksize = 3)\n",
    "sobely_8u_normal = np.uint8(np.absolute(sobely_normal))\n",
    "    \n",
    "edges_normal = sobelx_8u_normal + sobely_8u_normal\n",
    "\n",
    "sobelx = cv.Sobel(img, cv.CV_64F, 1, 0, ksize = 3)\n",
    "sobelx_8u = np.uint8(np.absolute(sobelx))\n",
    "\n",
    "sobely = cv.Sobel(img, cv.CV_64F, 0, 1, ksize = 3)\n",
    "sobely_8u = np.uint8(np.absolute(sobely))\n",
    "    \n",
    "edges = sobelx_8u + sobely_8u\n",
    "\n",
    "cv.imshow('result', np.hstack((edges_normal, edges)))\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64c328",
   "metadata": {},
   "source": [
    "### part c: Laplacian of Gaussian (LoG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c816513",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('electronic.jfif', 0)\n",
    "img_blur = cv.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "laplacian = cv.Laplacian(img_blur, cv.CV_64F, ksize = 1)\n",
    "laplacian_8u = np.uint8(np.absolute(laplacian))\n",
    "\n",
    "cv.imshow('result', laplacian_8u)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16fed99",
   "metadata": {},
   "source": [
    "In my opinion, the Laplacian of Gaussian pathway with smaller kernel size (1) would be optimal. As Laplacian filter is susceptible to noise, after removing the noise by Gaussian blur, the result seems satisfactory compared to the second path with Gaussian blur. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d7987",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3387183",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('pineapple.jfif', 0)\n",
    "img_blur = cv.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "# sobel\n",
    "\n",
    "sobelx = cv.Sobel(img_blur, cv.CV_64F, 1, 0, ksize = 3)\n",
    "sobelx_8u = np.uint8(np.absolute(sobelx))\n",
    "\n",
    "sobely = cv.Sobel(img_blur, cv.CV_64F, 0, 1, ksize = 3)\n",
    "sobely_8u = np.uint8(np.absolute(sobely))\n",
    "    \n",
    "edges = sobelx_8u + sobely_8u\n",
    "\n",
    "# Laplacian\n",
    "laplacian = cv.Laplacian(img_blur, cv.CV_64F, ksize = 3)\n",
    "laplacian_8u = np.uint8(np.absolute(laplacian))\n",
    "\n",
    "# Prewitt\n",
    "kernelx = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])\n",
    "kernely = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
    "\n",
    "img_prewittx = cv.filter2D(img_blur, -1, kernelx)\n",
    "img_prewitty = cv.filter2D(img_blur, -1, kernely)\n",
    "\n",
    "img_prewitt = img_prewittx + img_prewitty\n",
    "\n",
    "# Scharr\n",
    "sX = cv.Scharr(img_blur, cv.CV_64F, 1, 0, 3)\n",
    "sX = np.uint8(np.absolute(sX))\n",
    "sY = cv.Scharr(img_blur, cv.CV_64F, 0, 1, 3)\n",
    "sY = np.uint8(np.absolute(sY))\n",
    "s = sX + sY\n",
    "\n",
    "# Canny\n",
    "edges_canny = cv.Canny(img_blur, 100, 200)\n",
    "\n",
    "cv.imshow('result', np.hstack((edges, laplacian_8u, img_prewitt, s, edges_canny)))\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0957713a",
   "metadata": {},
   "source": [
    "Based on the result shown, the most preferable edge detection method would be Canny. Since it has more noise immunity than other methods and we can establish inferior and superior threshold for it.\n",
    "\n",
    "The worst one would be the Scharr method by referring to the result as it is very sensitive to noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef985d2f",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2b2f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('electronic.jfif')\n",
    "\n",
    "# white color boundaries [R, G, B]\n",
    "lower = [160, 160, 160]\n",
    "upper = [255, 255, 255]\n",
    "\n",
    "# create NumPy arrays from the boundaries\n",
    "lower = np.array(lower, dtype = \"uint8\")\n",
    "upper = np.array(upper, dtype = \"uint8\")\n",
    "\n",
    "# find the colors within the specified boundaries and apply the mask\n",
    "mask = cv.inRange(img, lower, upper)\n",
    "output = cv.bitwise_and(img, img, mask = mask)\n",
    "\n",
    "ret,thresh = cv.threshold(mask, 40, 255, 0)\n",
    "\n",
    "contours, hierarchy = cv.findContours(thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n",
    "\n",
    "if len(contours) != 0:\n",
    "    # draw in blue the contours that were founded\n",
    "    cv.drawContours(output, contours, -1, 255, 3)\n",
    "\n",
    "    # find the biggest countour (c) by the area\n",
    "    c = max(contours, key = cv.contourArea)\n",
    "    x, y, w, h = cv.boundingRect(c)\n",
    "\n",
    "    # draw the biggest contour (c) in green\n",
    "    cv.rectangle(img,(x,y),(x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# show the images\n",
    "cv.imshow(\"Result\", np.hstack([img, output]))\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e846201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
